#!/bin/bash

# è®¾ç½®ç¯å¢ƒå˜é‡ - Qwen2-1.5B-Instructæ¨¡å‹
export QWEN_MODEL_PATH="/models/qwen_backup/Qwen2-1___5B-Instruct"

# ç¦ç”¨ Hugging Face è¿œç¨‹ä¸‹è½½
export HF_DATASETS_OFFLINE=1
export TRANSFORMERS_OFFLINE=1

echo "ğŸš€ å¼€å§‹ Qwen2-1.5B-Instruct 10K token æµ‹è¯•ï¼ˆä½¿ç”¨ç®€å•è¯„ä¼°å™¨ï¼‰..."

python3 -m needlehaystack.run \
  --provider qwen \
  --model_name "Qwen2-1.5B-Instruct" \
  --evaluator simple \
  --context_lengths_min 10000 \
  --context_lengths_max 10000 \
  --context_lengths_num_intervals 1 \
  --document_depth_percent_min 0 \
  --document_depth_percent_max 100 \
  --document_depth_percent_intervals 10 \
  --num_concurrent_requests 1 \
  --save_results true \
  --save_contexts false \
  --final_context_length_buffer 200

echo "âœ… æµ‹è¯•å®Œæˆï¼ç»“æœä¿å­˜åœ¨ /workspace/results/ ç›®å½•ä¸‹"